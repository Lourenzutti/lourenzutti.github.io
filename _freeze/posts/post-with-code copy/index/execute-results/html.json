{
  "hash": "d54b2e02062dafd57783210e750d9116",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Module 6: Simulation-based hypothesis testing\"\nimage: \"image.jpg\"\ndraft: true\ndraft-mode: unlinked\nformat: live-html\nbibliography: references.bib\nwebr:\n  packages:\n    - tidyverse\n    - infer\n    - broom\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n## Learning objectives {.unnumbered}\n\n- Give an example of a question you could answer with a hypothesis test.\n\n- Differentiate composite vs. simple hypotheses.\n\n- Given an inferential question, formulate null and alternative hypotheses to be \nused in a hypothesis test.\n\n- Identify the steps and components of a basic hypothesis test (\"there is only \none hypothesis test\").\n\n- Write computer scripts to perform hypothesis testing via simulation, \nrandomization and bootstrapping approaches, as well as interpret the output.\n\n- Describe the relationship between confidence intervals and hypothesis testing.\n\n- Discuss the potential limitations of this simulation approach to hypothesis \ntesting.\n\n## Introduction {.unnumbered}\n\nSo far in the course, we have focused our attention on estimation, where we are \ninterested in unknown parameters of a specific population. Our objective was to \nestimate these unknown parameters as accurately as possible. We discussed two \ntypes of estimators:\n\n- Point estimators: just a number we calculate from our sample (i.e., a statistic).\n\n- Interval estimators: a range of plausible values for a parameter which \naccounts for the uncertainty associated with the estimation process \n(i.e., confidence intervals).\n\nHowever, in many situations, we are not mainly interested in the precise value \nof the parameter. Instead, we need to assess specific claims or assumptions \nabout the population, which can lead to different conclusions or decisions. To \nbetter understand this, let us consider the Vancouver Beaches problems \nintroduced in the example below.\n\n:::{#exm-vancouver-beach}\nDuring the summer, Vancouver’s beaches get pretty busy. To ensure everybody’s \nsafety, the city of Vancouver monitors if the beaches’ waters are safe for \nswimming.  If the average number of E. coli per $100$mL is $400$ or less, the \ncity considers the beach proper for swimming. Otherwise, the city of Vancouver \nreleases a public statement to warn people that they should not swim on the \nbeach. How should the city proceed?\n\n&#9633;\n:::\n\nIn @exm-vancouver-beach above, we have two competing statements: (1) the beach \nis safe for swimming (i.e., the average number of E. Coli per $100$mL is $400$ \nor less); and (2) the beach is unsafe for swimming (i.e., the average number of \nE. Coli per $100$mL is higher than $400$). The city's responsibility is to \ndetermine which of these statements holds true and to communicate the findings \nclearly to the public. Their primary objective is not to obtain an exact \nmeasurement of the average E. Coli level, but rather to ascertain whether it \nfalls at or below the threshold of $400$. The specific numerical values, such as \nwhether the average is $75$ or $100$ E. Coli per $100$ milliliters, are less \nimportant; what matters is the city's ability to confidently and reliably \nidentify which statement regarding the beach's safety is accurate. \n\nStatistical hypothesis testing provides a structured framework for evaluating \nthe strength of evidence contained in a dataset against specific claims or \nassumptions regarding a broader population. In this chapter, we will delve into \nthe methodology of conducting statistical tests designed to assess various \nhypotheses related to population characteristics. We'll explore the principles \nbehind these tests, the types of hypotheses that can be evaluated, and the \nprocedures for drawing conclusions based on the analysis of the data. Through \nthis discussion, we aim to equip you with the necessary tools to statistically \nassess the validity of claims about a population.\n\n\n<!--To test the water quality of a beach, the city of Vancouver takes multiple samples of the water and calculates the average number of E. coli (bacteria) per $100$mL.-->\n\n\n## Statistical Hypotheses: Null vs Alternative\n\nLet us start by defining what a hypothesis is.\n\n:::{#def-hypothesis}\n\n## Statistical Hypothesis\n\nA statement about one or more populations. \n\n:::\n\nAlthough the @def-hypothesis is quite broad, a hypothesis usually involves a \nstatement about *population parameters*.  Therefore, in this book, we will \nrestrict our attention to hypotheses that are statements about a population \nparameters. \n\nIn statistical hypothesis testing, we *always* have two competing and \ncomplementary hypotheses: the **null hypothesis** (denoted as $H_0$) and the \n**alternative hypothesis** (denoted as $H_A$ or $H_1$). The null hypothesis \nrepresents a default or status quo assumption about the population parameter, \noften reflecting a lack of effect or no difference. Conversely, the alternative \nhypothesis represents the claim or effect for which we are trying to find \nevidence. The goal of hypothesis testing is to assess whether the sample data \nprovides sufficient evidence to reject the null hypothesis in favor of the \nalternative hypothesis. \n\n\n### Hypotheses involving one population\n\nWhen we are testing only one parameter of a given population, we usually have a threshold of interest, which we call $\\mu_0$ (for the mean; read *mu naught*) and $p_0$ (for the proportion; read *p naught*), and the null hypothesis will have the following form:\n\n$$\nH_0: \\mu = \\mu_0 \n$$\n\nand the alternative hypothesis will have **one** (and only one) of the following three forms:\n\n- $H_A: \\mu < \\mu_0$\n- $H_A: \\mu > \\mu_0$\n- $H_A: \\mu \\neq \\mu_0$\n\nNaturally, in the case above, we are testing the mean. But we could be testing any other parameter. For example, for proportion, we would replace $\\mu$ with $p$: $H_0: p = p_0$. Let's see a few examples. \n\n:::{#exm-flu-vaccine}\nA pharmaceutical company has developed a new flu vaccine and wants to determine \nif it's more effective than the standard flu vaccine currently in use. The \nstandard vaccine is known to be effective in preventing the flu in 60% of the \npopulation who receive it. The company conducts a clinical trial where a random \nsample of individuals receives the new vaccine. Is the new vaccine more \neffective than the standard vaccine? The hypotheses are:\n\n$$\nH_0: p = 0.60 \\quad\\quad\\text{vs}\\quad\\quad H_A: p > 0.60\n$$\n\n&#9633;\n\n:::\n\n\nFrequently, as in the example above, we can unambiguously identify the null \nhypothesis. But sometimes, it depends on the problem. See the following two \nexamples.\n\n:::{#exm-LDL-heart}\nHeart disease is one of the leading causes of death worldwide, and high \ncholesterol is a significant risk factor. Medical guidelines recommend that the \naverage level of low-density lipoprotein (LDL), often referred to as \"bad\" \ncholesterol, should be below 100 mg/dL to help minimize the risk of heart \ndisease.\n\nIn Canada, the government is considering a new community health initiative aimed \nat reducing heart disease deaths. This initiative would cost approximately $1.23 \nbillion annually. The Official Opposition Party is urging the government to \navoid unnecessary expenditures. As a compromise, the government has stated that \nit drop the project if there is strong evidence showing that the Canadian \npopulation has a lower risk of heart disease due to low cholesterol levels. \n\nIn this case, we have \n$$\nH_0: \\mu = 100\\text{mg/dL}\\quad\\quad\\text{vs}\\quad\\quad H_A: \\mu < 100\\text{mg/dL}\n$$\nTherefore, our hypotheses are statements about the mean LDL cholesterol in the \nCanadian population. Also, note that the \ngovernment is demanding evidence to believe Canadians are low risk (as opposed \nto requiring evidence that Canadians are high risk). For this reason, we have \nthe \"low risk\" case in the alternative hypothesis. \n\nAlternatively, if the government had said that they would only proceed with the \nprogram if there were strong evidence that Canadians are at high risk of heart \ndisease, then we would formulate the hypotheses as:\n\n$$\nH_0: \\mu = 100\\text{mg/dL}\\quad\\quad\\text{vs}\\quad\\quad H_A: \\mu > 100\\text{mg/dL}\n$$\n\n&#9633;\n\n:::\n\n:::{#exm-vancouver-beach-hypotheses}\n\nGoing back to the Vancouver Beaches example (@exm-vancouver-beach). If the city \ncouncil works under the assumption that the beaches are usually improper for \nswimming (status-quo), they will require evidence that the beaches are safe for swimming.\nIn this case, \n$$\nH_0: \\mu = 400\\quad\\quad\\text{vs}\\quad\\quad H_A: \\mu < 400\n$$\n\nAlternatively, the city council could claim that it is very expensive to close \nthe beaches, and they want to do it only if they have evidence that the beaches\nare not safe for swimming. Then: \n\n$$\nH_0: \\mu = 400\\quad\\quad\\text{vs}\\quad\\quad H_A: \\mu > 400\n$$\n\n&#9633;\n:::\n\nIn statistical hypothesis testing, we begin by assuming that one of two hypotheses, $H_0$ (the null hypothesis) or $H_A$ (the alternative hypothesis), is true. However, we do not know which one it is, and our goal is to determine that. A common question that arises is: what if neither hypothesis is true? \n\nFor example, let’s consider the situation presented by @exm-flu-vaccine. The hypotheses are defined as follows: $H_0: p = 0.6$ versus $H_A: p > 0.6$. But what if the vaccine actually has a negative effect? This raises the possibility that, after receiving the vaccine, $p$ could be **less** than 0.6. If we believe this scenario is a real possibility, we could redefine the null hypothesis to be $H_0: p \\leq 0.6$ versus $H_A: p > 0.6$. This way, we encompass all possible outcomes within our two hypotheses.\n\nFortunately, for the tests discussed in this book, this adjustment does not affect the results of the hypothesis test. Therefore, the conclusions will remain the same whether we use $H_0: p = 0.6$ or $H_0: p \\leq 0.6$. For this reason, we will always express the null hypothesis using the equal sign as follows: $H_0: p = p_0$.\n\n### Hypotheses involving two populations\n\nWhen comparing two populations, we are often interested in examining the values of their parameters. Typically, the null hypothesis is stated as:\n\n$$\nH_0: \\mu_1 - \\mu_2 = \\Delta_0\n$$\nThe alternative hypothesis could take one of the following forms:\n\n- $H_A: \\mu_1-\\mu_2 < \\Delta_0$\n- $H_A: \\mu_1-\\mu_2 > \\Delta_0$\n- $H_A: \\mu_1-\\mu_2 \\neq \\Delta_0$\n\nLet's see some examples.\n\n:::{#exm-diff-prop-hypotheses}\n*Tech Solutions*, a software company, is testing two different versions of their website's landing page. They want to know if one version leads to a higher proportion of visitors signing up for a free trial. They randomly assign website visitors to either version A or version B. They track the number of visitors who sign up for a free trial on each version. In this case, the hypotheses are:\n$$\nH_0: p_1-p_2=0 \\quad\\quad \\text{ vs } \\quad\\quad H_A: p_1-p_2\\neq0\n$$\nwhere $p_1$ and $p_2$ are the proportion of sign-ups for versions A and B, respectively. Or, in another words: \n\n- $H_0$: There is no difference in the proportion of visitors who sign up for a free trial between the two landing page versions.\n\n- $H_A$: There is a difference in the proportion of visitors who sign up for a free trial between the two landing page versions.\n\nNote that in this case, we used $\\Delta_0 = 0$.\n\n&#9633;\n:::\n\n:::{#exm-diff-means-hypothese}\n\"Green Thumb Gardens\" wants to test two different fertilizer types to see which promotes better plant growth. They are specifically interested in the average height of tomato plants after a certain period. They take a batch of young tomato plants and randomly assign them to two groups. Group A receives \"Fertilizer GrowFast,\" and Group B receives \"Fertilizer BloomBoost.\" After six weeks, they measure the height of each plant in centimetres. They want to determine if there is a difference in the average height of tomato plants between the two fertilizer groups.\n\n\n$$\nH_0: \\mu_1-\\mu_2=0 \\quad\\quad \\text{ vs } \\quad\\quad H_A: \\mu_1-\\mu_2\\neq0\n$$\nwhere $\\mu_1$ is the mean height of plants using Fertilizer GrowFast, and $\\mu_2$ is the mean height of plants using Fertilizer BloomBoost. Or, in words: \n\n- $H_0$: There is no difference in the average height of tomato plants between the two fertilizer groups.\n\n- $H_A$: There is a difference in the average height of tomato plants between the two fertilizer groups.\n\n&#9633;\n:::\n\nWith a clear understanding of how to define statistical hypotheses, we are now equipped to delve into the mechanics of hypothesis testing.\n\n<!--### Conclusion\n\nIn this section, we have laid the groundwork for understanding statistical hypothesis testing by defining what a hypothesis is and exploring how to formulate both null and alternative hypotheses. We've seen that hypotheses can be about a single population parameter or about the relationship between parameters from two or more populations. Crucially, we've emphasized that the null hypothesis typically represents a status quo or no-effect scenario, while the alternative hypothesis embodies the claim we are seeking evidence for. Through various examples, we've demonstrated how to translate real-world questions into testable statistical hypotheses, setting the stage for the next step in the process: hypothesis testing.\n\n-->\n\n### Exercises\n\n\n## The idea of hypothesis testing\n\nTesting hypotheses is similar to being a detective. Detectives do not witness crimes directly; instead, they determine who committed a crime based on the aftermath. This process typically involves considering various scenarios (or hypotheses) and checking whether the evidence collected supports or contradicts them. Importantly, detectives look for evidence that *contradicts* the \"innocent\" hypothesis. This is similar to the principle of \"innocent until proven guilty\" (in statistics, we assume the null hypothesis is true until we find sufficient evidence to reject it).\n\n#### How does this relate to statistics? {.unnumbered}\n\nThe null hypothesis, denoted as H0, is either true or false, but we cannot \nobserve it directly—similar to how a detective does not witness the crime being \ncommitted. We are unable to observe it directly because we do not have access to \nthe entire population, which means we do not know the true value of the \nparameter.\n\nHowever, the null hypothesis, H0, implies a specific sampling distribution for \nsome statistics (the aftermath). We can then take a sample and contrast the \nvalue of the statistic against the sampling distribution if H0 were true.\n\nLet's revisit our example with @exm-flu-vaccine. Suppose we take a sample of 50 \npatients. Since we are testing the population proportion, we can use the sample \nproportion $\\hat{p}$ to gain insights about the population mean. \n[**If the null hypothesis were true**]{style='color: darkred;'}, we know from \nthe Central Limit Theorem (CLT) that \n$\\hat{p} \\sim N\\left(0.6, \\sqrt{\\frac{0.6 \\times 0.4}{50}}\\right)$. If we used \ndifferent values for $p_0$ in $H_0$, the sampling distribution would change \naccordingly. See the plot below.\n\n<br>\n\n:::{#fig-sampling-dist-flu style='text-align:center;'}\n\n\n\n```{ojs}\n//| echo: false\n\nviewof p0 = Inputs.range([0.4, 0.6], {\n  step: 0.01,\n  value: 0.6,\n  label: \"Null hypothesis proportion (p₀)\"\n})\n\nPlot.plot({\n  y: {\n    domain: [0, 4]\n  },\n  marks: [\n    Plot.line(\n      d3.range(0, 1, 0.001).map(p => ({\n        p,\n        density: Math.exp(-Math.pow((p - p0), 2) / (2 * (p0 * (1 - p0) / 50))) /\n                Math.sqrt(2 * Math.PI * (p0 * (1 - p0) / 50))\n      })),\n      {\n        x: \"p\",\n        y: \"density\"\n      }\n    ),\n    Plot.ruleY([0])\n  ],\n  grid: true,\n  width: 640,\n  height: 400,\n  x: {\n    label: \"Sample Proportion\"\n  },\n  y: {\n    label: \"Density\"\n  }\n})\n```\n\n\n\nThe sampling distribution of $\\hat{p}$ assuming $H_0: p=p_0$ is true.\n\n:::\n\n<br>\n\n\nThe plot above illustrates the sampling distribution of the sample proportion \nassuming the null hypothesis is true. As you adjust the value of $p_0$, the \ndistribution shifts accordingly.\n\nFinally, we can collect the data (the evidence), calculate the sample proportion \n$\\hat{p}$, and compare it to the sampling distribution under the null hypothesis \n$H_0$. If the calculated value of the statistic is plausible under $H_0$, we do \nnot have enough evidence to reject the hypothesis. For instance, in the case of \n@exm-flu-vaccine, where $p_0 = 0.6$, suppose that after collecting our sample, \nof size 50 we calculate a sample proportion of $\\hat{p} = 0.95$. The sampling\ndistribution and the statistic are shown in @fig-null-model-idea-low-pvalue. \n\n:::{#fig-null-model-idea-low-pvalue}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThe sampling distribution of $\\hat{p}$ in @exm-flu-vaccine for a sample of size\n50 and an observed $\\hat{p}=0.95$ (in red), assuming $H_0$ is true. \n:::\n\nAs noted by @fig-null-model-idea-low-pvalue, the observed value of $\\hat{p}$ in \nour sample is $\\hat{p} = 0.95$. This value is **VERY** unlikely to occur if the \nnull hypothesis $H_0$ is true. Therefore, we have two possibilities: either we \nwere simply unlucky and ended up with an unusual sample, or the null hypothesis \n$H_0$ is false. This suggests that the distribution shown in @fig-null-model-idea-low-pvalue \ndoes not accurately represent the true sampling distribution of $\\hat{p}$. \nThis situation is akin to a detective finding the murder weapon with the \nsuspect's fingerprint on it. While this evidence strongly suggests the suspect's \nguilt, it does not conclusively prove it. \n\nLet’s consider an alternative scenario where we collect a sample of size $50$, \nand the sample proportion is $\\hat{p} = 0.65$. In this case, it wouldn’t be \nsurprising to observe this $\\hat{p}$ value if the null hypothesis $H_0$ were \ntrue (see @fig-null-model-idea-high-pvalue). Therefore, the observed value of \n$\\hat{p}$ does not contradict the hypothesis $H_0$, indicating that the evidence \nagainst $H_0$ is weak. However, this does not imply that $H_0$ is true; it \nsimply means that we lack strong evidence to reject it. It's similar to a \ndetective who cannot find conclusive evidence against a suspect; this absence of \nevidence does not prove the suspect's innocence. In other words, the absence of \nevidence of guilt is not the same as evidence of innocence.\n\n:::{#fig-null-model-idea-high-pvalue}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nThe sampling distribution of $\\hat{p}$ in @exm-flu-vaccine for a sample of size\n50 and an observed $\\hat{p}=0.65$ (in red), assuming $H_0$ is true. \n\n:::\n\nNow that we've seen how the core idea of hypothesis testing involves comparing our data to what we'd expect under the null hypothesis. But how do we actually do that in practice? The next section will provide a detailed, step-by-step guide to the hypothesis testing procedure, equipping you with the tools to apply these concepts to real-world problems.\"\n\n### The steps in hypothesis testing {.numbered}\n\nIn this book, we will discuss different strategies for hypothesis testing as \nwell as many different hypothesis tests. However, no matter the strategy and the \ntest, we will always be guided by five steps.\n\n#### **Step 1: Formulate the Hypotheses** {.unnumbered}\n\nIn this step, it is essential to clearly define the null hypothesis ($H_0$) and \nthe alternative hypothesis ($H_A$). Often, this step in the research process \ndoes not receive adequate attention, but formulating these hypotheses is crucial. \nThey guide our statistical analysis and help determine the appropriate tests to \nuse in evaluating the evidence against the null hypothesis. This is the stage \nwhere you translate your research problem into a statistical problem, and this \n\"translation\" needs to be carefully considered. Otherwise, the conclusions drawn \nmay not adequately address the original question.\n\n#### **Step 2: Define the desired significance level** {.unnumbered}\n\n\nTo decide whether to reject or not $H_0$, we need to determine whether the evidence against $H_0$ is strong. In @fig-null-model-idea-low-pvalue, we argued that the $\\hat{p}=0.95$ was highly unlikely to happen if $H_0$ was true and that evidence was very strong against $H_0$. On the other hand, in @fig-null-model-idea-high-pvalue, we argued that a $\\hat{p}$ around $0.65$ would not be unusual if $H_0$ were true, so the evidence against $H_0$ was weak.   But at what point did the evidence go from \"strong\" (@fig-null-model-idea-low-pvalue) to \"weak\" (@fig-null-model-idea-high-pvalue)? Try changing the value of the sample proportion in @fig-evidence-strength. \n\n:::{#fig-evidence-strength}\n\n\n\n```{ojs}\n//| echo: false\nviewof phat = Inputs.range([0, 1], {\n  step: 0.01,\n  value: 0.5,\n  label: tex`\\hat{p}`\n});\n\nPlot.plot({\n  style: {\n    fontSize: \"14px\"\n  },\n  y: {\n    domain: [0, 4]\n  },\n  marginBottom: 60,  // Only increase bottom margin for x-axis label\n  marks: [\n    Plot.line(\n      d3.range(0, 1, 0.001).map(p => ({\n        p,\n        density: Math.exp(-Math.pow((p - 0.6), 2) / (2 * (0.6 * (1 - 0.6) / 50))) /\n                Math.sqrt(2 * Math.PI * (0.6 * (1 - 0.6) / 50))\n      })),\n      {\n        x: \"p\",\n        y: \"density\",\n        stroke: \"black\"\n      }\n    ),\n    Plot.ruleY([0]),\n    Plot.ruleX([phat], { stroke: phat < 0.72 ? \"#2e7d32\" : \"red\", strokeWidth: 2 }),\n    Plot.text(\n      [{x: 0.2, y: 3.8, text: phat >= 0.72 ? \"evidence: strong\" : \"evidence: weak\"}],\n      {\n        x: \"x\",\n        y: \"y\",\n        text: \"text\",\n        fill: phat >= 0.72 ? \"red\" : \"#2e7d32\",\n        fontSize: 18\n      }\n    )\n  ],\n  grid: true,\n  width: 640,\n  height: 440,\n  x: {\n    label: \"Sample Proportion\",\n    labelOffset: 40\n  },\n  y: {\n    label: \"Density\"\n  }\n})\n```\n\n\n\nStrength of evidence against $H_0$ for different values of $\\hat{p}$. \nWhen the vertical line is red, it would result in the rejection $H_0$. If green,\nnon-rejection of $H_0$. Note that the vertical line will be determined by your \nsample. \n\n:::\n\n\nAs you can see above, the evidence against $H_0$ was considered strong (as in we\nwould reject $H_0$) for $\\hat{p}$ as low as $0.72$. However, for $\\hat{p}=0.71$ \nthe evidence against $H_0$ was now considered weak (as in we would not reject \n$H_0$). But why did we use this threshold? Here comes the significance level. \n\nThe significance level, commonly denoted by $\\alpha$ (/ˈæl.fə/), determines \nwhether the evidence is sufficiently compelling to warrant the rejection of the \nnull hypothesis in favour of the alternative hypothesis. \n\nThe significance level is a probability (therefore, it is between $0$ and $1$) that \nindicates the likelihood of incorrectly rejecting the null hypothesis when the \nnull hypothesis is, in fact, true — this error is known as a Type I Error. Let's \nformally define both of these concepts. \n\n:::{#def-type-I-error}\n## Type I Error\n\nThe error that occurs when $H_0$ is true but is rejected. \n:::\n\n:::{#def-significance-level}\n## Significance Level\n\nThe probability of Type I Error.\n\n:::\n\nSignificance level and Type I Error can be too abstract and confusing \nwhen first learning about it. Let us discuss an example. \n\n\n:::{#exm-vaccine-alpha}\nThe standard flu vaccine is known to be effective in preventing the flu in $60\\%$ of the population that receives it. A questionable pharmaceutical company has obtained the recipe for this standard flu vaccine and has created $1000$ variants by making minor tweaks to the recipe. They are aware that these small modifications will not affect the vaccine's effectiveness. Nevertheless, they plan to apply for a license to sell these variants with the U.S. Food and Drug Administration (FDA). \n\nFor each vaccine, the FDA will conduct an experimental study to test the following hypotheses: \n$$H_0: p = 0.6\\quad\\quad\\text{ vs }\\quad\\quad H_A: p > 0.6$$\n\nSince the modified vaccines are known to have the same effectiveness as the standard flu vaccine, the FDA should reject the license applications for all $1000$ vaccines. However, with a significance level set at $5\\%$, it is expected that approximately $5\\%$ of the $1000$ vaccines (around $50$ vaccines) will have their licenses approved despite not meeting the necessary criteria. \n\nIn this context: \n\n- The hypothesis of no improvement is represented by $H_0$. \n\n- $H_0$ is known to be true in this scenario. \n\n- Rejecting $H_0$ would result in granting permission to sell the vaccine, which should not occur since $H_0$ is true. This case would be the Type I Error.\n\n- Consequently, around the $\\alpha\\times 1000$ (in this case, $\\alpha=5\\%$) of the license applications will be mistakenly approved.\n\n&#9633;\n\n:::\n\nAlthough the value of $\\alpha$ can range from 0 to 1, we generally prefer smaller values. It's important to note that $\\alpha$ represents the probability of an error, specifically the probability of rejecting the null hypothesis when it is actually true. Typical values of $\\alpha$ are $1\\%$, $5\\%$, and $10\\%$.\n\n#### **Step 3: Identify an appropriate test statistic** {.unnumbered}\n\nIn this step, we choose a statistic (i.e., a function of the sample data) that allows us to assess the compatibility of the data with the null hypothesis. Since we will use this statistic for hypothesis testing, we call it test statistics.\n\n:::{#def-hypothesis}\n\n## Test statistic\n\nA statistic used to test hypothesis.\n\n:::\n\nThe choice of the test statistic depends on the parameter being tested (e.g., mean, proportion), the number of populations being compared, and the assumptions about the data. Examples of test statistics include the sample mean, the difference between two sample means, or a sample proportion.\n\nTest statistics are not unique; we can use different test statistics for the same hypothesis tests. However, these statistics may exhibit varying performances, which can be measured by their probabilities of making errors. As will be discussed later, we often use different (but equivalent) statistics when applying simulation-based methods compared to those based on mathematical models.\n\n\n#### **Step 4: Identify the Null Model** {.unnumbered}\n\nAs we did in the flu vaccine example (@exm-flu-vaccine), we need to figure out the distribution of the test statistic if the null hypothesis is true. This distribution is called the **null model**.\nThis distribution is crucial because it allows us to determine how likely it is to observe the value of the test statistic calculated from our sample if the null hypothesis was indeed true.\n\n:::{#def-hypothesis}\n\n## Null model\n\nThe sampling distribution of the test statistic if the null hypothesis is true.\n\n:::\n\nIt is at this stage that we pretend that a scenario is true (the null hypothesis) and see if the statistic we obtained from the sample we have collected is compatible with this scenario. In the detective analogy, this is the stage where the detective imagines a scenario and tries to figure out if the evidence collected is compatible with this scenario:\n\n> \"If a person is innocent, it would be very unlikely for me to find their fingerprint in the crime weapon. But I found their fingerprint in the crime weapon. Therefore, the innocent hypothesis seems incompatible with the evidence.\"\n\n\n:::{#exm-null-model-flu-vaccine}\nBy identifying the null model, we create a baseline against which we can compare our observed sample statistic. For instance, if we observe a sample proportion of $\\hat{p}=0.95$, as shown in @fig-null-model-idea-low-pvalue, we can see how unlikely this observation would be under the null model. Conversely, an observation like $\\hat{p}=0.65$, as in @fig-null-model-idea-high-pvalue, is more plausible under the null model. Therefore, the null model provides the framework for assessing the evidence against the null hypothesis.\n:::\n\n&#9633;\n\n#### **Step 5: Compute the p-value and make a decision** {.unnumbered}\n\nThis is the final step in the hypothesis-testing process. The p-value measures the strength of the evidence against the null hypothesis. It can be tricky to interpret the p-value, but you could think about the p-values as a measure of how compatible the data is with the null hypothesis. High p-values suggest that the data is compatible with the null hypothesis, while low p-values indicate that the data is incompatible with the null hypothesis.\n\n:::{#def-p-value}\n\n## p-value\n\nThe probability, under the null model, of observing a test statistic at least as extreme as the one observed in the sample data, in favor of $H_A$.\n\n:::\n\nThe definition of the p-value is quite abstract, but it is easier to understand with an example. \n\n:::{#exm-p-value-flu-vaccine}\n\nLet's revisit the flu vaccine example (@exm-flu-vaccine). We are testing the hypotheses:\n$$\nH_0: p = 0.6 \\quad\\quad\\text{vs}\\quad\\quad H_A: p > 0.6\n$$\n\nSuppose we take a sample of $50$ patients and observe that $45$ of them are protected from the flu by the new vaccine. Since we are testing the population\nproportion, let us use the sample proportion as the test statistic for this test. Now, if $H_0$ is true what is the sampling distribution of $\\hat{p}$? This is the null model and it is shown in @fig-null-model-flu-vaccine.\n\n:::{#fig-null-model-flu-vaccine}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nThe sampling distribution of $\\hat{p}$ assuming $H_0: p=0.6$ is true (i.e., the null model).\n\n:::\n\nGreat! According to the null model (i.e., assuming $H_0$ is true), we would expect to observe a $\\hat{p}$ around $0.5$ and $0.7$. If we end up observing a $\\hat{p}$, say, around $0.9$, we are either very \"unlucky\" or $H_0$ is not true. Imagine we obtained a sample proportion $\\hat{p}=35/50=0.7$ as shown in @fig-p-value-flu-vaccine-with-obs-test-statistic.\n\n:::{#fig-p-value-flu-vaccine-with-obs-test-statistic}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\nThe null model when $H_0: p=0.6$ is true and the value of the test statistic.\n\n:::\n\nTo calculate the p-value we want the probability of observing a $\\hat{p}$ being at least as extreme as the one we observed (i.e., $0.7$). under the null model **in favour of the alternative hypothesis**. We know that the alternative hypothesis states that $p>0.6$. So the \"alternative\" side of the distribution is the right side. The p-value is the area to the right of the observed test statistic. This is shown in @fig-p-value-flu-vaccine-pvalue.\n\n:::{#fig-p-value-flu-vaccine-pvalue}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\nThe proportion of points in the red bins is the p-value, which in this case is 0.0771.\n\n:::\n\nIn this case, the p-value is 0.0771. This means that if $H_0$ is true, only $7.71\\%$ of the possible samples would yield a $\\hat{p}$ of $0.7$ or higher. Is this too rare, suggestion that $H_0$ is false? To answer this question, we need to compare the p-value to the significance level. If the p-value is less than the significance level, we reject $H_0$. Otherwise, we do not have enough evidence to reject $H_0$.\n\n&#9633;\n:::\n\n:::{.callout-important}\np-value is a conditional probability. Conditioned on $H_0$ being true. This condition comes into play because we use the null model to calculate the p-value.\n:::\n\nNext, let's break down the definition of p-value:\n\n> The p-value is the $\\underbrace{\\text{probability, under the null model}}_{\\#1}$, of observing a $\\underbrace{\\text{test statistic at least as extreme as the one observed in the sample data}}_{\\#2}$, $\\underbrace{\\text{in favour of }H_A}_{\\#3}$.\n\nLet's dissect this definition:\n\n- $\\#1$: The p-value is a probability, which means it ranges from 0 to 1. We can calculate as the area under the curve in mathematical models, or counting the proportions of points in simulation-based methods.\n\n- $\\#2$: This tells us the threshold for \"extreme\", which is the observed test statistic.\n\n- $\\#3$: This part brings the alternative hypothesis into play. It defines the direction that we consider \"extreme\". The area on the right? on the left? or both sides?\n\nThe point $\\#3$ above determines the type of test we are conducting. There are three types of tests:\n\n#### **Left-tailed test ($H_A: \\theta < \\theta_0$)**\n\nIf the alternative hypothesis is of the form $H_A: \\theta < \\theta_0$, where $\\theta$ is any parameter of interest, the p-value is the area on the left of the observed test statistic ($\\leq$ -- equal sign included), as shown in @fig-p-value-flu-vaccine-pvalue-left-tailed below.\n\n\n\n```{ojs}\n//| echo: false\n\n// Generate fixed simulated data\nsimulatedData = {\n  function getRandomNumber(min, max) {\n    return Math.random() * (max - min) + min;\n  }\n  const n = 2000;\n  const data = [];\n  for (let i = 0; i < n; i++) {\n    const u1 = getRandomNumber(0,1);\n    const u2 = getRandomNumber(0,1);\n    const z = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);\n    data.push(z);\n  }\n  return data;\n}\n```\n\n\n\n:::{#fig-p-value-flu-vaccine-pvalue-left-tailed}\n\n\n```{ojs}\n//| echo: false\nviewof statistic_left_tail = {\n  const input = Inputs.range([-4, 4], {\n    step: 0.1,\n    value: 0,\n    label: \"Test Statistic\"\n  });\n  \n  d3.select(input).select('input[type=\"number\"]').style(\"display\", \"none\");\n\n  return input\n}\n\n// Create histogram data\nhistogram_data_left_tail = d3.bin()\n  .domain([-4, 4])\n  .thresholds(20)\n  (simulatedData)\n  .map(bin => ({\n    x0: bin.x0,\n    x1: bin.x1,\n    count: bin.length\n  }));\n\n{\n  const chartWidth = 640;\n  const chartHeight = 440;\n  const marginBottom = 60;\n  const marginLeft = 60;\n  const marginRight = 120;\n  const marginTop = 40;\n\n  const x = d3.scaleLinear()\n    .domain([-4, 4])\n    .range([marginLeft, chartWidth - marginRight]);\n\n  const y = d3.scaleLinear()\n    .domain([0, d3.max(histogram_data_left_tail, d => d.count)])\n    .range([chartHeight - marginBottom, marginTop]);\n\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", chartWidth)\n      .attr(\"height\", chartHeight);\n\n  // Add title\n  svg.append(\"text\")\n      .attr(\"x\", chartWidth / 2)\n      .attr(\"y\", 25)\n      .attr(\"text-anchor\", \"middle\")\n      //.style(\"font-size\", \"20px\")\n      //.style(\"font-weight\", \"bold\")\n      .text(\"p-value region for a left-tailed test\");\n\n  // Add X axis without numbers\n  svg.append(\"g\")\n      .attr(\"transform\", `translate(0, ${chartHeight - marginBottom})`)\n      .call(d3.axisBottom(x).tickFormat(\"\"));\n\n  // Add custom tick for observed test statistic\n  svg.append(\"text\")\n      .attr(\"x\", x(statistic_left_tail))\n      .attr(\"y\", chartHeight - marginBottom + 20)\n      .attr(\"text-anchor\", \"middle\")\n      .text(\"Observed Test Statistic\");\n\n  // Add X axis label\n  svg.append(\"text\")\n      .attr(\"transform\", `translate(${chartWidth / 2}, ${chartHeight - 20})`)\n      .style(\"text-anchor\", \"middle\")\n      .text(\"Test Statistic\");\n\n  // Add Y axis without numbers\n  svg.append(\"g\")\n      .attr(\"transform\", `translate(${marginLeft}, 0)`)\n      .call(d3.axisLeft(y).tickFormat(\"\"));\n\n  // Add Y axis label\n  svg.append(\"text\")\n      .attr(\"transform\", \"rotate(-90)\")\n      .attr(\"y\", 0)\n      .attr(\"x\", 0 - (chartHeight / 2))\n      .attr(\"dy\", \"1em\")\n      .style(\"text-anchor\", \"middle\")\n      .text(\"Count\");\n\n  // Steelblue part of the bars (now for values greater than statistic)\n  svg.selectAll(\".steelblue-bar\")\n    .data(histogram_data_left_tail)\n    .enter()\n    .append(\"rect\")\n    .attr(\"class\", \"steelblue-bar\")\n    .attr(\"x\", d => x(Math.max(d.x0, statistic_left_tail)))\n    .attr(\"y\", d => y(d.count))\n    .attr(\"width\", d => Math.max(0, x(d.x1) - x(Math.max(d.x0, statistic_left_tail))))\n    .attr(\"height\", d => chartHeight - marginBottom - y(d.count))\n    .attr(\"fill\", \"steelblue\")\n    .attr(\"stroke\", \"white\");\n\n  // Red part of the bars (now for values less than or equal to statistic)\n  svg.selectAll(\".red-bar\")\n    .data(histogram_data_left_tail)\n    .enter()\n    .append(\"rect\")\n    .attr(\"class\", \"red-bar\")\n    .attr(\"x\", d => x(d.x0))\n    .attr(\"y\", d => y(d.count))\n    .attr(\"width\", d => Math.max(0, x(Math.min(d.x1, statistic_left_tail)) - x(d.x0)))\n    .attr(\"height\", d => chartHeight - marginBottom - y(d.count))\n    .attr(\"fill\", \"red\")\n    .attr(\"stroke\", \"white\");\n\n  svg.append(\"line\")\n      .attr(\"x1\", x(statistic_left_tail))\n      .attr(\"x2\", x(statistic_left_tail))\n      .attr(\"y1\", y(0))\n      .attr(\"y2\", y(d3.max(histogram_data_left_tail, d => d.count)))\n      .attr(\"stroke\", \"red\")\n      .attr(\"stroke-width\", 2);\n\n  // Calculate and display p-value (changed to left-tail)\n  const p_value = histogram_data_left_tail.filter(d => d.x1 <= statistic_left_tail)\n    .reduce((sum, d) => sum + d.count, 0) / d3.sum(histogram_data_left_tail, d => d.count);\n\n  // Moved p-value text left and up\n  svg.append(\"text\")\n      .attr(\"x\", chartWidth - marginRight - 20)\n      .attr(\"y\", chartHeight / 3)\n      .style(\"text-anchor\", \"start\")\n      .text(`p-value: ${p_value.toFixed(3)}`);\n\n  return svg.node();\n}\n```\n\n\n\nThe probability that the test statistic is **lower** than the observed values of the test statistic in the current sample, assuming $H_0$ is true.\n:::\n\n\n#### **Right-tailed test ($H_A: \\theta > \\theta_0$)**\n\nIf the alternative hypothesis is of the form $H_A: \\theta > \\theta_0$, where $\\theta$ is any parameter of interest, the p-value is the area on the left of the observed test statistic ($\\geq$ -- equal sign included), as shown in @fig-p-value-flu-vaccine-pvalue-right-tailed.\n\n:::{#fig-p-value-flu-vaccine-pvalue-right-tailed}\n\n\n```{ojs}\n//| echo: false\nviewof statistic = {\n  const input = Inputs.range([-4, 4], {\n    step: 0.1,\n    value: 0,\n    label: \"Test Statistic\"\n  });\n  \n  d3.select(input).select('input[type=\"number\"]').style(\"display\", \"none\");\n\n  return input\n}\n\n// Create histogram data\nhistogram_data_right_tailed = d3.bin()\n  .domain([-4, 4])\n  .thresholds(20)\n  (simulatedData)\n  .map(bin => ({\n    x0: bin.x0,\n    x1: bin.x1,\n    count: bin.length\n  }));\n\n{\n  const chartWidth = 640;\n  const chartHeight = 440;\n  const marginBottom = 60;\n  const marginLeft = 60;\n  const marginRight = 120;\n  const marginTop = 40;  // Added margin top\n\n  const x = d3.scaleLinear()\n    .domain([-4, 4])\n    .range([marginLeft, chartWidth - marginRight]);\n\n  const y = d3.scaleLinear()\n    .domain([0, d3.max(histogram_data_right_tailed, d => d.count)])\n    .range([chartHeight - marginBottom, marginTop]);  // Updated to account for top margin\n\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", chartWidth)\n      .attr(\"height\", chartHeight);\n\n  // Add title\n  svg.append(\"text\")\n      .attr(\"x\", chartWidth / 2)\n      .attr(\"y\", 25)\n      .attr(\"text-anchor\", \"middle\")\n      .style(\"font-size\", \"16px\")\n      .text(\"p-value region for a right-tailed test\");\n\n  // Add X axis without numbers\n  svg.append(\"g\")\n      .attr(\"transform\", `translate(0, ${chartHeight - marginBottom})`)\n      .call(d3.axisBottom(x).tickFormat(\"\"));\n\n  // Add custom tick for observed test statistic\n  svg.append(\"text\")\n      .attr(\"x\", x(statistic))\n      .attr(\"y\", chartHeight - marginBottom + 20)\n      .attr(\"text-anchor\", \"middle\")\n      .text(\"Observed Test Statistic\");\n\n  // Add X axis label\n  svg.append(\"text\")\n      .attr(\"transform\", `translate(${chartWidth / 2}, ${chartHeight - 20})`)\n      .style(\"text-anchor\", \"middle\")\n      .text(\"Test Statistic\");\n\n  // Add Y axis without numbers\n  svg.append(\"g\")\n      .attr(\"transform\", `translate(${marginLeft}, 0)`)\n      .call(d3.axisLeft(y).tickFormat(\"\"));\n\n  // Add Y axis label\n  svg.append(\"text\")\n      .attr(\"transform\", \"rotate(-90)\")\n      .attr(\"y\", 0)\n      .attr(\"x\", 0 - (chartHeight / 2))\n      .attr(\"dy\", \"1em\")\n      .style(\"text-anchor\", \"middle\")\n      .text(\"Count\");\n\n  // Gray part of the bars\n  svg.selectAll(\".gray-bar\")\n    .data(histogram_data_right_tailed)\n    .enter()\n    .append(\"rect\")\n    .attr(\"class\", \"gray-bar\")\n    .attr(\"x\", d => x(d.x0))\n    .attr(\"y\", d => y(d.count))\n    .attr(\"width\", d => Math.max(0, x(Math.min(d.x1, statistic)) - x(d.x0)))\n    .attr(\"height\", d => chartHeight - marginBottom - y(d.count))\n    .attr(\"fill\", \"steelblue\")\n    .attr(\"stroke\", \"white\");\n\n  // Red part of the bars\n  svg.selectAll(\".red-bar\")\n    .data(histogram_data_right_tailed)\n    .enter()\n    .append(\"rect\")\n    .attr(\"class\", \"red-bar\")\n    .attr(\"x\", d => x(Math.max(d.x0, statistic)))\n    .attr(\"y\", d => y(d.count))\n    .attr(\"width\", d => Math.max(0, x(d.x1) - x(Math.max(d.x0, statistic))))\n    .attr(\"height\", d => chartHeight - marginBottom - y(d.count))\n    .attr(\"fill\", \"red\")\n    .attr(\"stroke\", \"white\");\n\n  svg.append(\"line\")\n      .attr(\"x1\", x(statistic))\n      .attr(\"x2\", x(statistic))\n      .attr(\"y1\", y(0))\n      .attr(\"y2\", y(d3.max(histogram_data_right_tailed, d => d.count)))\n      .attr(\"stroke\", \"red\")\n      .attr(\"stroke-width\", 2);\n\n  // Calculate and display p-value\n  const p_value = histogram_data_right_tailed.filter(d => d.x0 >= statistic)\n    .reduce((sum, d) => sum + d.count, 0) / d3.sum(histogram_data_right_tailed, d => d.count);\n\n  // Moved p-value text left and up\n  svg.append(\"text\")\n      .attr(\"x\", chartWidth - marginRight - 20)\n      .attr(\"y\", chartHeight / 3)\n      .style(\"text-anchor\", \"start\")\n      .text(`p-value: ${p_value.toFixed(3)}`);\n\n  return svg.node();\n}\n```\n\n\n\nThe probability that the test statistic is **higher** than the observed values of the test statistic in the current sample, assuming $H_0$ is true.\n:::\n\n#### **Two-tailed test ($H_A: \\theta \\neq \\theta_0$)**\n\nNow consider the alternative hypothesis is of the form $H_A: \\theta \\neq \\theta_0$, where $\\theta$ is any parameter of interest. To calculate the p-value in this case, we follow these four steps:\n\n1. Calculate the p-value as if the test were a right-tailed test: $p_{\\text{right}}$.\n2. Calculate the p-value as if the test were a left-tailed test: $p_{\\text{left}}$.\n3. Select the smaller of $p_{\\text{right}}$ and $p_{\\text{left}}$, then multiply it by 2.\n4. Finally, since the p-value is a probability, ensure it does not exceed 1.\n\nIn mathematical terms, this can be expressed as: \n$p = \\min\\{1, 2p_{\\text{right}}, 2p_{\\text{left}}\\}$. This approach is called *twice-the-smaller-tail* [@thulin2024modern].\n\n\n### Exercises\n\n<!-- For them to practice p-value:\nprovide them with a context for hypothesis test, provide the hypothes2s. Give them the null model. \n  (1) the nullmodel as mathematical distribution;\n  (2) the null as a simulated dataframe in a variable for them to code.\n  (3) Create several versions of this question for each type of test (left-tailed, right-tailed, two-tailed)\nAsk them to calculate the p-value. -->\n\n## Simulation-based hypothesis testing\n\nThe challenging aspect of hypothesis testing lies in identifying the test statistic and its null model. The null model represents the sampling distribution of the test statistic, assuming the null hypothesis is true. As we have seen before, we can investigate the sampling distribution of the test statistic via simulation-based approaches and mathematical approximations.\n\nIn this chapter, we will concentrate on simulation-based methods, while the mathematical approach will be covered in the next chapter. The fundamental idea behind simulation-based methods is to simulate values from the null model and use these simulated values to approximate the p-value.\n\n### One population\n\nIn this section, we will focus on problems involving a single parameter of a given population.\n\n#### Test for one mean ($\\mu$)\n\nLet us go back again to @exm-vancouver-beach. During the summer, Vancouver's beaches get pretty busy. To ensure everybody's safety, the city of Vancouver monitors if the beaches' waters are safe for swimming. To test the water quality of a beach, the city of Vancouver takes multiple samples of the water and calculates the average number of E. coli (bacteria) per $100$ mL. If the average number of E. coli per $100$mL is $400$ or less, the city considers the beach proper for swimming. Otherwise, the city of Vancouver releases a warning to let people know that they should not swim on the beach. The city wants to test if the water is unsafe.\n\nSuppose that right before the summer, the city of Vancouver is going to test the water at Kitsilano Beach. Given the cost of closing a beach, the City of Vancouver wants to do that only if there's strong evidence that they should do it. They set the hypotheses:\n\n$$\nH_0: \\mu = 400\\quad\\quad\\text{vs}\\quad\\quad H_A: \\mu > 400\n$$\n\nTo test the hypothesis, the technicians took $59$ samples of $100$ mL at different points of the beach. The data is available in the variable `kits_sample` in the code cell below. \n\n\n\n\n::: {.cell autorun='true' edit='false'}\n```{webr}\n#| output: false\n#| autorun: true\n#| edit: false\n#|\nset.seed(1)\n\nkits_ecoli_sample <- rnorm(59, 415, 85.68)\nkits_sample <- tibble(\n  e_coli = round(kits_ecoli_sample - mean(kits_ecoli_sample) + 415)\n)\n\nsample_mean <- mean(kits_sample$e_coli)\nsample_sd <- sd(kits_sample$e_coli)\n```\n:::\n\n::: {.cell}\n```{webr}\n####################################\n# Sample data from Kitsilano Beach #\n####################################\nkits_sample\n```\n:::\n\n\n\nLet's examine the sample data more closely.\n\n\n\n::: {.cell}\n```{webr}\n##############################################\n# Calculate sample mean and sample std. dev. #\n##############################################\nsample_mean <- mean(kits_sample$e_coli)\nsample_sd <- sd(kits_sample$e_coli)\n\n# Print the value of the statistics\ncat(\"Sample mean:\", sample_mean)\ncat(\"Sample std. dev.:\", sample_sd)\n\n################################\n# Plot the sample distribution #\n################################\nkits_sample %>%\n  ggplot() + \n  geom_histogram(aes(e_coli), \n                 color = 'white',\n                 fill = 'steelblue', \n                 bins = 10) + \n  ggtitle(\"Sample Distribution of E. Coli per 100mL in 59 samples from Kitsilano Beach\") + \n  xlab('E. Coli') + \n  theme_bw()\n```\n:::\n\n\n\nNow that we have the data, we need to determine if our sample is \"compatible\" with the null hypothesis. The null hypothesis states that the population mean is equal to 400 E. coli. Therefore, if the null hypothesis is true, we would expect the sample mean to be close to 400. This suggests that the sample mean is a reasonable test statistic in this context. But how close does the sample mean need to be to 400? To answer this question, we must consider what the sampling distribution of the sample would look like if the null hypothesis were true; this represents the null model.\n\nWe learned that we can use bootstrapping to approximate the sampling distribution of $\\bar{X}$. \n\n\n\n::: {.cell}\n```{webr}\n#######################################\n# Generate the bootstrap distribution #\n# based on kits_sample.               #   \n#######################################\nboot_dist <- \n  kits_sample %>%\n  rep_sample_n(size = 59, replace=TRUE, reps = 10000) %>%\n  summarise(xbar = mean(e_coli))\n\n###################################\n# Plot the bootstrap distribution #\n###################################\nboot_dist %>%\n  ggplot() + \n  geom_histogram(aes(xbar), \n                 color = 'white', \n                 fill = 'steelblue', \n                 bins = 20) +\n  ggtitle('Bootstrap Distribution') + \n  xlab('Avg. E. Coli per 100mL') +\n  theme_bw()\n```\n:::\n\n\n\nThe issue with the Bootstrap Distribution generated above is that it attempts to approximate the true sampling distribution, rather than representing the sampling distribution when the null hypothesis $H_0$ is true, which corresponds to the null model. Therefore, if $H_0$ is false, the Bootstrap distribution does not reflect the null model. \n\nTo adapt our code to generate samples from the null model instead of the sampling distribution, we need to incorporate the information provided by the null hypothesis. In this example, the null hypothesis asserts that $\\mu = 400$, indicating that the mean of the null model is $400$. To create our null model, we can shift our sample distribution so that its mean is $400$. Remember, the mean of the boostrap distribution in this case is the sample mean, so this shift will make the bootstrap distribution to be centered at $400$ as specified by our null hypothesis. The code is very similar to generate the bootstrap distribution with only one extra step that centers the sample distribution at $\\mu_0$ (in this case $\\mu_0 = 400$). \n\n\n\n::: {.cell}\n```{webr}\n##################################################\n# Approximating the null model via Bootstrapping #\n##################################################\nnull_model <- \n  kits_sample %>%\n  mutate(e_coli = e_coli - mean(e_coli) + 400) %>%  \n  rep_sample_n(size = 59, replace=TRUE, reps = 10000) %>%\n  summarise(xbar = mean(e_coli))\n\n#######################\n# Plot the null model #\n#######################\nnull_model %>%\n  ggplot() + \n  geom_histogram(aes(xbar), \n                 color = 'white', \n                 fill = 'steelblue', \n                 bins = 20) +\n  ggtitle('Null model via Simulation') + \n  xlab('Avg. E. Coli per 100mL') +\n  theme_bw()\n```\n:::\n\n\n\nAs you can see, the only difference here is the inclusion for the line `mutate(e_coli = e_coli - mean(e_coli) + 400)`. Here's how it works: \n\nThe expression `e_coli - mean(e_coli)` centers the mean of the sample at 0. The spread remains the same. By adding $400$ to this result, we shift the mean of the sample to 400. In other words, `e_coli - mean(e_coli) + 400` makes the sample mean to be $400$. Again, the mean of the boostrap distribution in this case is the sample mean, which now will be $400$, as specified in $H_0$. Therefore, the distribution above is the sampling distribution of $\\bar{X}$ when the null hypothesis is true, i.e., the null model. \n\nAt this point, we understand how our test statistic, $\\bar{X}$, behaves if $H_0$ is true. But how does the observed value of the test statistic in our specific sample compare to the null model? Specifically, we want to determine how likely it is to obtain a value for the test statistic that is equal to or greater than our observed mean.\n\n\n\n::: {.cell}\n```{webr}\n##################################################\n# Plot the null model vs Observed Test Statistic #\n##################################################\nnull_model %>%\n  ggplot() + \n  geom_histogram(aes(xbar), \n                 color = 'white', \n                 fill = 'steelblue', \n                 bins = 20) +\n  geom_vline(aes(xintercept = sample_mean), color='red') + \n  annotate(\"rect\", \n           xmin = sample_mean, xmax = Inf, \n           ymin = -Inf, ymax = Inf,\n           alpha = .2, \n           fill = 'red') +\n  ggtitle('Null model via Simulation vs Test Statistic') + \n  xlab('Avg. E. Coli per 100mL') +\n  theme_bw()\n```\n:::\n\n\n\nThe observed test statistic is positioned at the right tail of the null model, indicating that such a high sample average is somewhat unlikely to occur when the null hypothesis is true. But just how unlikely is it? To determine this, we can calculate the proportion of all possible samples that would result in a sample average at least as high as the one we observed if the null hypothesis were true. This value is known as the p-value.\n\n\n\n::: {.cell}\n```{webr}\n#####################\n# Calculate p-value #\n#####################\n(pvalue <- mean(null_model$xbar >= sample_mean))\n\n# Note that here, we are checking whether the \n# mean generated from the null model is \n# higher than or equal to the mean in our sample. \n```\n:::\n\n\n\nThis means that if $H_0$ were true, only 5% of the samples would give us a sample mean as high as or higher than the observed sample mean. Were we very unlucky of selecting such a rare sample, or is $H_0$ false? To make this decision we compare the p-value against the significance level. For example, for a significance level of $\\alpha = 10\\%$, we have that $\\text{p-value} < \\alpha$, and we reject $H_0$. In this case we say:\n\n> There is enough evidence at $10\\%$ significance level to reject the hypothesis that the average count of E. Coli per $100$ mL in the Kitsilano beach is 400 in favour of the alternative hypothesis that the average is higher than 400.\n\nFor $\\alpha = 5\\%$, we have that $\\text{p-value} > \\alpha$, and in this case, we would not reject $H_0$:\n\n> There is not enough evidence at $5\\%$ significance level to reject the null hypothesis that the average count of E. Coli per $100$ mL in the Kitsilano beach is 400 in favour of the alternative hypothesis that the average is higher than 400.\n\nIt is important to note that the significance level must be defined before looking at the data. \nYou must not adjust your significance level to reach the conclusion you desire. \n\n##### The `infer` workflow {.unnumbered}\n\nAlthough the workflow above is helpful for us to explore the process of \nsimulation-based hypothesis testing, the `infer` package [@infer2021] provides a more \nconvenient way to do this, which is very similar to the workflow we have used \nfor confidence intervals. To simulate from the null model, we just need to add one extra line.  \n\n\n\n\n::: {.cell}\n```{webr}\n###########################################\n# Infer workflow: generate the null model #\n###########################################\nnull_model_infer <- \n  kits_sample %>%\n  specify(response = e_coli) %>%\n  hypothesize(mu = 400, null = 'point') %>%\n  generate(reps = 20000, type = 'bootstrap') %>%\n  calculate(stat = 'mean')\n\n# Let's take a look:\nnull_model_infer %>% head()\n```\n:::\n\n\n\nThe only function from this workflow we haven't seen before is the [hypothesize](https://infer.netlify.app/reference/hypothesize) function. The `hypothesize` function defines the null hypothesis (i.e., we define the parameter of interest and its value under $H_0$). In this case, we are saying: `null = point`, which tells `infer` that we want to test only one parameter. To specify the parameter to be tested and its value under $H_0$, we passed `mu = 400`. The `mu` says that we are testing the mean (we could have said `p = ...` [for proportion] or `med = ...` [for the median]), and `400` specifies the value of $\\mu_0$. \n\nThe variable `null_model_infer` stores the simulated values from the null model. \nTo get the p-value, we can use the `get_p_value` function (or its alias `get_pvalue`).\nFor the `get_p_value` function, you need to specify the observed test statistic and the\ndirection of the test, in this case the observed sample mean and `right`-tailed test.\n\n\n\n::: {.cell}\n```{webr}\n###############################\n# Infer workflow: get p-value #\n###############################\nnull_model_infer %>%\n  get_p_value(sample_mean, direction = 'right')\n```\n:::\n\n\n\nFinally, to visualize the test, we can use the `visualize` function combined with\nthe `shade_pvalue`.\n\n\n\n::: {.cell}\n```{webr}\n##################################################\n# Infer workflow: visualize the test and p-value #\n##################################################\nnull_model_infer %>%\n  visualize() + \n  shade_pvalue(sample_mean, direction = 'right')\n```\n:::\n\n\n\n\n#### Test for one median ($Q_{0.5}$)\n\nThe case of the median is very similar to the mean. Let's go over the procedures with an example.\n\n:::{#exm-senate-hearing}\nA Senate hearing is currently investigating consumer complaints regarding airlines in the United States. During one of the sessions, the CEO of American Airlines was questioned about the time it takes for the company to resolve customer support tickets. The CEO stated that the median resolution time is 48 hours, indicating that 50% of the tickets are resolved in 48 hours or less. In response to this claim, the Senate hearing committee decided to conduct a further investigation. They collected a sample of 100 support tickets and examined the resolution times in hours, which are recorded in the `support_time` variable.The senate will test the hypothesis \n$$\nH_0: Q_{0.5} = 48 \\quad\\quad vs \\quad\\quad H_A: Q_{0.5} > 48\n$$\nand if there is enough evidence at $5\\%$ significance level, the senate will issue a fine to American Airlines. \n\n\n\n::: {.cell autorun='true' edit='false'}\n```{webr}\n#| autorun: true\n#| output: false\n#| edit: false\nset.seed(1)\n\nsupport_time <- tibble(\n  time_hrs = 18 * (abs(rt(100, 1))+2)\n)\n\nsupp_time_median <- median(support_time$time_hrs)\n```\n:::\n\n::: {.cell}\n```{webr}\n####################################\n# Sample data from support tickets #\n####################################\nsupport_time %>% head()\n\n(supp_time_median <- median(support_time$time_hrs))\n```\n:::\n\n::: {.cell}\n```{webr}\n############################\n# Plot sample distribution #\n############################\nsupport_time %>%\n  ggplot() +\n  geom_histogram(aes(time_hrs), \n                 color = 'white', \n                 fill = 'steelblue',\n                 bins = 20) + \n  xlab(\"Resolution Time (hrs)\") + \n  ggtitle(\"Sample distribution of American Airline support tickets\") + \n  theme_bw()\n```\n:::\n\n\n\nNext, we will simulate values from the null model. We cannot simply resample \nfrom our sample because this approach will not accurately represent the null \nmodel if the null hypothesis ($H_0$) is false. However, similar to how we might \nadjust for the mean, we can shift our sample so that the median matches the \nvalue specified in $H_0$, which is 48 hours.\n\n\n\n\n::: {.cell}\n```{webr}\n##################################################\n# Approximating the null model via Bootstrapping #\n##################################################\nnull_model_supp_time <- \n  support_time %>%\n  mutate(time_hrs = time_hrs - median(time_hrs) + 48) %>%\n  rep_sample_n(size = 100, reps = 15000, replace = TRUE) %>%\n  summarise(q_50 = median(time_hrs))\n```\n:::\n\n\n\nFinally we can calculate the p-value.\n\n\n\n::: {.cell}\n```{webr}\n##########################\n# Calculate the p-value. #\n##########################\n(p_value <- mean(null_model_supp_time$q_50 > supp_time_median))\n```\n:::\n\n\n\nSince the p-value is approximately 31%, the Senate does not have enough evidence at a 5% significance level to reject the American Airlines CEO's claim that the median time to resolve a support ticket is 48 hours.\n\nAgain, the `infer` workflow makes this entire analysis more convenient. To generate from the null model using the infer workflow in this case:\n\n\n\n::: {.cell}\n```{webr}\n###########################################\n# Infer workflow: generate the null model #\n###########################################\nnull_model_supp_time_infer <- \n  support_time %>%\n  specify(response = time_hrs) %>%\n  hypothesise(null = 'point', med = 48) %>%\n  generate(reps = 15000, type = \"bootstrap\") %>%\n  calculate(stat = \"median\")\n```\n:::\n\n\n\nNext, we obtain the p-value.\n\n\n\n::: {.cell}\n```{webr}\n##################################\n# Infer workflow: Obtain p-value #\n##################################\nnull_model_supp_time_infer %>%\n  get_p_value(obs_stat = supp_time_median, direction = 'right')\n```\n:::\n\n\nFinally, the `visualize` function gives us an overall picture of the test.\n\n\n\n::: {.cell}\n```{webr}\n##################################\n# Infer workflow: visualize test #\n##################################\nnull_model_supp_time_infer %>%\n  visualise() +\n  shade_pvalue(obs_stat = supp_time_median, direction = 'right')\n```\n:::\n\n\n\n:::\n\n#### Test for one proportion ($p$)\n\nSuppose we want to test $H_0: p = p_0$ against one of $H_A: p\\neq p_0$, $H_A: p > p_0$, or $H_A: p < p_0$. Since we want to test the proportion, it is natural to use the sample proportion as our test statistic. \n\nHere, again, we want to simulate the null distribution. However, the procedure differs slightly from the mean and median one. \nThis is because, for proportion, we cannot simply shift the distribution. \nRemember that the standard error of $\\hat{p}$ is given by $SE(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}$, which depends on $p$. So, it is not possible for us to shift the sample distribution without also affecting the standard error of the statistic. \n\nHowever, in the case of proportions, we know that every element in our population can either be a 0 (indicating that they do not possess the attribute we are examining) or a 1 (indicating that they do possess the attribute). The challenge is that we do not know the exact proportion of each category. Essentially, it is like having a bar chart with one bar representing zeros and another for ones, but we simply do not know the height of each bar. \n\n\n\n```{ojs}\n//| echo: false\nviewof p = Inputs.range([0.1, 0.9], {\n  step: 0.01,\n  value: 0.5,\n  label: \"Population proportion\"\n})\n\nPlot.plot({\n  y: {\n    axis: null,\n    domain: [0, 1]\n  },\n  x: {\n    ticks: [0, 1],\n    tickFormat: d => d,\n    label: null\n  },\n  marks: [\n    Plot.barY([\n      { category: 0, proportion: 1 - p },\n      { category: 1, proportion: p }\n    ], {\n      x: \"category\",\n      y: \"proportion\",\n      fill: \"steelblue\"\n    }),\n    Plot.text([0, 1], {\n      x: [0, 1],\n      y: [-0.05, -0.05],\n      text: d => d,\n      dy: 20,\n      fontSize: 16\n    }),\n    Plot.text([\"Population distribution\"], { // Title as a text mark\n      x: [0.5],          // Center horizontally (midpoint of 0 and 1)\n      y: [.95],         // Position at the top (slightly above 1)\n      fontWeight: \"bold\", // Make it bold\n      fontSize: 22,       // Set font size\n      textAnchor: \"middle\" // Center the text horizontally\n    })\n  ]\n})\n```\n\n\n\nLuckily for us, $H_0: p = p_0$ tell us exactly the size of each of the bar if the null hypothesis were true. So, we know exactly what our population would look like under $H_0$. Therefore, we can `draw` new values directly from the population under the null hypothesis, and we don't need to resample from our sample. \n\n:::{#exm-obesity}\nAccording to the National Institute of Diabetes and Digestive and Kidney Diseases, [approximately 42.5% of adults in the United States are classified as obese](https://www.niddk.nih.gov/health-information/health-statistics/overweight-obesity). The new Health Secretary aims to launch a campaign that encourages Americans to adopt better eating habits and lead healthier lifestyles. As part of this initiative, a series of new policies has been implemented. After two years, the House of Representatives plans to evaluate the effectiveness of the program to determine if there has been any change in the obesity rate. They have surveyed a random sample of 300 adults, with the data available in the `obesity_study` variable. The objective is to test the hypothesis: $H_0: p = 0.425$ versus $H_A: p \\neq 0.425$ at a $5\\%$ significance level.\n\n\n\n::: {.cell edit='false' autorun='true'}\n```{webr}\n#| edit: false\n#| output: false\n#| echo: false\n#| autorun: true\n\nset.seed(1)\nobesity_study <- tibble(\n  is_obese = rbinom(300, size = 1, prob = 0.40)\n) %>%\n  mutate(is_obese = if_else(is_obese == 1, \"yes\", \"no\"))\nsample_prop_obese <- mean(obesity_study$is_obese == \"yes\")\n```\n:::\n\n::: {.cell}\n```{webr}\n#############################\n# Sample data obesity study #\n#############################\nobesity_study \n\n(sample_prop_obese <- mean(obesity_study$is_obese == \"yes\"))\n```\n:::\n\n\n\nTo test the hypotheses, we will use the sample proportion. Our next step is to generate value from the null model. But note that $H_0$ specifies what our population looks like. So, to \"estimate\" the null model, we can take multiple samples directly from this would-be population if $H_0$ were true. To sample from this distribution, we randomly select between `\"yes\"` or `\"no\"` with the probability of `\"yes\"` equals to $p_0=0.425$. \n\n\n\n::: {.cell}\n```{webr}\n#####################################\n# Storing the values of the problem #\n#####################################\nsample_size = 300\nreps = 10000\np0 = 0.425\n\n################################################\n# Null model: two steps                        #\n#   1. Take multiple samples from the          #\n#      theoretical population (under H0);      #\n#   2. Calculate the sample proportion of each # \n#      sample to obtain the null model.        #\n################################################\nnull_model_obesity <- tibble(\n    replicate = rep(1:reps, sample_size),\n    is_obese = sample(c('yes', 'no'), \n                      size = sample_size * reps,\n                      prob = c(p0, 1-p0),\n                      replace = TRUE)\n  ) %>%\n  group_by(replicate) %>%\n  summarise(sim_phat = mean(is_obese == 'yes'))\n\nnull_model_obesity \n```\n:::\n\n\n\nLet's examine the null model and the observed test statistics.\n\n\n\n::: {.cell}\n```{webr}\n#####################################\n# Plot the simulated null model and #\n# the observed test statistic.      #\n#####################################\nnull_model_obesity %>%\n  ggplot() + \n  geom_histogram(aes(x = sim_phat), \n                 fill = 'steelblue', \n                 color = 'white',\n                 bins = 15) + \n  geom_vline(xintercept = sample_prop_obese, color = 'red') + \n  ggtitle('Null Model via Simulation') + \n  xlab('Simulated proportions') + \n  theme_bw()\n```\n:::\n\n\n\nIn the plot above, we can see that the test statistic is located on the left side. This means that our sample proportion of obese individuals, as $\\hat{p} = 0.37$, is smaller than the hypothesized proportion $p_0 = 0.425$. To calculate the p-value, we determine the proportion of simulated statistics that fall below our $\\hat{p} = 0.37$ and then multiply that proportion by $2$.\n\n\n\n::: {.cell}\n```{webr}\n###############\n# Get p-value #\n###############\nnull_model_obesity %>% \n  summarise(p_value = 2 * mean(sim_phat <= sample_prop_obese))\n```\n:::\n\n\n\nTherefore, at a $5\\%$ significance level, we fail to reject $H_0$. The conclusion is :\n\n> The House of Representatives doesn't have enough evidence to reject the null hypothesis that the obesity proportion is $42.5\\%$ in favour of $H_A$, that the obesity proportion is different from $42.5\\%$.\n\n\nFinally, once again, the `infer` workflow makes our life much easier. Let us take a look.\n\n\n\n::: {.cell}\n```{webr}\n###########################################\n# Infer workflow: generate the null model #\n###########################################\nnull_model_obesity_infer <- \n  obesity_study %>%\n  mutate(is_obese = is_obese) %>%\n  specify(response = is_obese, success = 'yes') %>%\n  hypothesise(null = 'point', p = 0.425) %>%\n  generate(reps = 10000, type = 'draw') %>%\n  calculate(stat = 'prop') \n```\n:::\n\n\nThere are two differences from the previous approach we used for the mean:  \n\n1. First, note that when we call `specify`, we must now define what is considered \"success\". For this study we have `specify(response = is_obese, success = \"yes\")`. \n2. Second, we need to specify that we want to generate from a theoretical population instead of resampling from the original sample. Therefore, in the `generate` function, we use `type = \"draw\"`. \n\nThe code above generates values from the theoretical population distribution if $H_0$ were true. Next, we can calculate the p-value and visualize the test. \n\n\n\n::: {.cell}\n```{webr}\n##################################\n# Infer workflow: visualize test #\n##################################\nnull_model_obesity_infer %>% \n  visualize() +\n  shade_pvalue(obs_stat = sample_prop_obese, direction = 'both')\n\n###############################\n# Infer workflow: get p-value #\n###############################\n(p_value_obese_infer <- null_model_obesity_infer %>%\n  get_p_value(obs_stat=sample_prop_obese, direction = 'both'))\n```\n:::\n\n\n:::\n\n\n### Two populations\n\nComing soon!!\n\n#### Difference in means\n\n#### Difference in proportions\n\n\n## Exercises\n\n<!--Supposed Tech Solutions in @exm-diff-prop-hypotheses wanted to see if the version B of the website yielded higher sign ups for free trial. Would $H_0$ and $H_A$ change? If yes, write the new hypotheses. -->\n\n<!--Supposed the Green Thumb Gardens in @exm-diff-means-hypotheses wanted to see if the Fertilizer GrowFast yields at least 5 cm higher growth compared to the Fertilizer BloomBoost. How would the hypotheses look like in this scenario?-->\n\n\n## References\n\n::: {#refs}\n\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}